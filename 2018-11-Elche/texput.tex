%%% Local Variables:
%%% mode: latex
%%% TeX-master: "<none>"
%%% End:

\title{Video Streaming using Icecast/P2PSP}
\author{\begin{tabular}{lr}Cristóbal Medina López & \texttt{cristobalmedinalopez@gmail.com}\\
    Juan Pablo García Ortiz & \texttt{jp.garcia.ortiz@gmail.com}\\
    Leocadio González Casado & \texttt{leo@ual.es} \\
    Vicente González Ruiz & \texttt{vruiz@ual.es} \\
    ~ & ~ \\
    \multicolumn{2}{c}{\href{http://www.hpca.ual.es/}{SAL, UAL}}\\
    \multicolumn{2}{c}{\vbox{\imgw{800}{graphics/thanks.png}}}
\end{tabular}}
%\author{\begin{tabular}{rl}
%    Cristóbal Medina López & \texttt{cristobalmedinalopez@gmail.com} \\
%    Juan Pablo García Ortiz & \texttt{} \\
%    Leocadio González Casado & \texttt{} \\
%    Vicente González Ruiz & \texttt{} \\
%    \multicolumn{2}{c}{\fig{600}{6cm}{FIGs/thanks.svg}}
%  \end{tabular}
%}
\date{Elche \\ November, 2018 \\ \url{https://github.com/P2PSP/slides}}

\maketitle

\begin{abstract}
  P2PSP (\url{https://p2psp.github.io}) is an application-layer
  protocol that provides real-time broadcasting, also known as
  Application Layer Multicast (ALM), of a media stream on the
  Internet. Peers collaborate to diseminate the stream that is
  generated by a single source, minimizing the latency and the
  protocol overhead. P2PSP overlays are push-based (topology-driven)
  meshes. To minimize the transmission latency, P2PSP establishes a
  communication between nearby peers, and chunks of data are flooded
  without explicit requests. P2PSP has a modular design organized in
  \emph{sets of rules}, where each module is especialized in
  implementing a different functionality.
\end{abstract}

\tableofcontents
\section{Internet transmission models}
\begin{tabular}{ccccc}
  MODE & TOPOLOGY & SCOPE & PROTOCOLS & APPLICATIONS/SYSTEMS \\
  \hline
  \href{https://en.wikipedia.org/wiki/Unicast}{Unicast} & \vbox{\imgw{200}{graphics/Unicast.svg}} & Whole network & \href{https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol}{HTTP} (\href{https://en.wikipedia.org/wiki/Transmission_Control_Protocol}{TCP}) & \href{https://www.reddit.com/r/networking/comments/2cp356/how_do_streaming_services_like_netflix_and/}{YouTube/Netflix} \\
  \href{https://en.wikipedia.org/wiki/Broadcasting_%28networking%29}{Broadcast} & \vbox{\imgw{200}{graphics/Broadcast.svg}} & Subnet (LAN) & \href{https://en.wikipedia.org/wiki/Address_Resolution_Protocol}{ARP} & - \\
    \href{https://en.wikipedia.org/wiki/Multicast}{Multicast} & \vbox{\imgw{200}{graphics/Multicast.svg}} & Defined horizon alg. (routers/TTL) & \href{https://en.wikipedia.org/wiki/Service_Location_Protocol}{SLP} (\href{https://en.wikipedia.org/wiki/User_Datagram_Protocol}{UDP}, \href{https://en.wikipedia.org/wiki/Session_Description_Protocol}{SDP}, \href{https://en.wikipedia.org/wiki/User_Datagram_Protocol}{UDP}) & \href{http://www.movistar.es/}{Movistar+}, \href{https://www.ono.es/television/}{Ono TV} \\
  \href{https://en.wikipedia.org/wiki/Anycast}{Anycast} & \vbox{\imgw{200}{graphics/Anycast.svg}} & Internet & \href{https://en.wikipedia.org/wiki/Domain_Name_System)}{DNS protocol} (\href{https://en.wikipedia.org/wiki/User_Datagram_Protocol}{UDP}) & \href{https://www.maxcdn.com/blog/anycast-ip-routing-used-maxcdn/}{CDNs}, \href{https://en.wikipedia.org/wiki/Domain_Name_System}{DNS}
  \end{tabular}

\section{Streaming models}
\begin{tabular}{ccc}
IP Multicast & IP Unicast and Client/Server Model & IP Unicast and P2P Model \\
\hline
\vbox{\imgw{300}{graphics/multicast-server.svg}} & \vbox{\imgw{300}{graphics/unicast-server.svg}} & \vbox{\imgw{300}{graphics/unicast-splitter.svg}}
\end{tabular}

\section*{Lab 1: Streaming with VLC}
\begin{center}
  \imgw{200}{graphics/VLC.svg}
\end{center}
\lstinputlisting{labs/lab1.sh}

\section*{Lab 2: Streaming with VLC and Icecast}
\begin{center}
  \imgw{300}{graphics/icecast-1.svg}
\end{center}
\lstinputlisting{labs/lab2.sh}

\section*{Lab 3: Relaying}
\begin{center}
  \imgw{500}{graphics/icecast-2.svg}
\end{center}
\begin{itemize}
  \item Icecast servers can be connected following a tree structure to
    increase scalability.
  \item All or a subset of the streams (channels) can be relayed
    between servers.
  \item Clients, the DNS (IP Anycast) or an intermediate server (which
    performs \href{https://en.wikipedia.org/wiki/URL_redirection}{HTTP
      redirection}) are in charge of selecting the most suitable
    server.
\end{itemize}
\lstinputlisting{labs/lab3.sh}

\section{ALM (Application-Layer Multicast) versus NLM (Network-Layer Multicast)}
\begin{center}
  \begin{tabular}{ccc}
  \vbox{\imgw{200}{graphics/NLM.svg}} & \vbox{\imgw{200}{graphics/CS-ALM.svg}} & \vbox{\imgw{200}{graphics/P2P-ALM.svg}} \\
  Network Layer Multicast             & Client/Server Application Multicast    & Peer-to-Peer Application Multicast
  \end{tabular}
\end{center}

\section{Push-based versus pull-based}
\begin{center}
  \begin{tabular}{cc}
    \vbox{\imgw{200}{graphics/push-based.svg}} & \vbox{\imgw{200}{graphics/pull-based.svg}} \\
    Push-based Protocol                        & Pull-based Protocol
  \end{tabular}
\end{center}

\section{P2PSP}
An \href{https://en.wikipedia.org/wiki/Multicast}{Application-layer Multicast} protocol which uses a push-based \href{https://en.wikipedia.org/wiki/Network_topology}{fully connected mesh} (when possible) \href{https://en.wikipedia.org/wiki/Overlay_network}{overlay} for real-time \href{(https://en.wikipedia.org/wiki/Streaming_media}{streaming of media content} between networked \href{https://en.wikipedia.org/wiki/Process_%28computing%29}{entities}. Example:

\begin{center}
  \imgw{400}{graphics/full-mesh.svg}
\end{center}

\subsection{DBS (Data Broadcasting Set of rules)}
DBS provides ALM~\cite{banerjee2002scalable} of a media stream in
unicast environments~\cite{comer2003computer}.
\begin{enumerate}
  \item The media is sent by a streaming server, and received by a
    \emph{splitter}.
  \item The splitter divides the stream into a sequence of chunks of
    data, and relay them to its \emph{team} using a round-robing
    schema.
  \item Each \emph{peer} gathers the chunks from the splitter and the
    rest of peers of the team, and sends them to a \emph{player}.
  \item Incoming peers receive from the splitter the list of peers of
    the team, and send to they a $[\text{hello}]$ message.
  \item When a peer receives a $[\text{hello}]$, incorporates the
    sender to a table $\text{forward}$. If peer $P_i$ has an entry
    $P_i: [P_j, P_k]$ in their forwarding table, each chunk originated
    at $P_i$ will be forwarded to $P_j$ and $P_k$.
  \item To perform data flow-control, peers write down in a table
    $\text{pending}$ all chunks that must be sent to each neighbor,
    which are selected using a round-robing scheduler when a new chunk
    is received.
\end{enumerate}

\begin{center}
  \begin{figure}
    \imgw{250}{graphics/team_0.svg} \caption{A team has been created
      with a single monitor $M_0$ ($[\mathtt{hello}]$ messages are not
      shown). Chunks with numbers 0 and 1 (the time $t$ is measured in
      chunks-time) have been transmitted from the splitter $S$ to
      $M_0$. $F$ and $P$ represents the $\text{forward}[]$ and the
      $\text{pending}[]$ structures, respectively. The chunks stored
      in the buffer is shown under the entity.\label{fig:team_0}}
  \end{figure}

  \begin{figure}
    \imgw{250}{graphics/team_1.svg} \caption{Peer $P_1$ joins the team
      (the $[\mathtt{hello}]$'s are not shown). In $M_0$,
      $F=\{M_0:[P_1]\}$ because when $M_0$ receives the
      $[\mathtt{hello}]$ from $P_1$, $M_0$ is the origin peer for all
      chunks received from $S$ and $P_1$ is its neighbor. $P_1$
      includes an entry $P_1:[M_0]$ in its forwarding table because
      $M_0$ is in the list of peers received from the splitter. After
      that, when the chunk number 2 arrives to $M_0$ from $S$, an
      entry $P_1:2$ is created in $P\{\}$ for that chunk, and this
      entry is deleted when the chunk 2 is sent to $P_1$. Notice that
      $P_1$ does not receive chunks 0 and 1 because these chunks
      belong to an old (already played) section of the
      stream.\label{fig:team_1}}
  \end{figure}

  \begin{figure}
    \imgw{300}{graphics/team_2.svg} \caption{$P_2$ joins the team
      (sending the $[\mathtt{hello}]$'s not shown). $M_0$ and $P_1$
      includes $P_2$ in their forwarding tables. The chunk 3 is
      received by $P_1$ which decides to send it to $P_2$. Chunk 3
      remains as pending to be sent to $M_0$ when the next chunk is
      received by $P_1$. $P_2$ is the origin peer for $M_0$ and $P_1$
      because both of them are in the list of peers that $P_2$
      receives from $S$. \label{fig:team_2}}
  \end{figure}

  \begin{figure}
    \imgw{330}{graphics/team_3.svg} \caption{Chunk 4 is received by
      $P_2$ which relays it to $P_1$, what relays chunk 3 to
      $M_0$.\label{fig:team_3}}
  \end{figure}

  \begin{figure}
    \imgw{330}{graphics/team_4.svg} \caption{Chunk 5 is received by
      $M_0$ which relays it to $P_2$.\label{fig:team_4}}
  \end{figure}

  \begin{figure*}
    \imgw{350}{graphics/team_5.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{380}{graphics/team_6.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{320}{graphics/team_7.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{200}{graphics/team_8.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{280}{graphics/team_9.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{350}{graphics/team_10.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{210}{graphics/team_11.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{210}{graphics/team_12.svg}
  \end{figure*}
  
  \begin{figure*}
    \imgw{210}{graphics/team_13.svg}
  \end{figure*}

\end{center}

\subsection{IMS (Ip Multicast Set of rules)}
IPM is available by default in LANs (Local Are Network)s and VLANs
(Virtual LANs)~\cite{shabtay2011ip}, but not in the
Internet~\cite{Comer1}. IMS runs on the top of DBS and provides
efficient native IPM, where available.

\begin{enumerate}
\item The idea of IMS is simple: all peers in the same LAN or VLAN
  have the same network address. When a joining peer $P_i$ receives
  the list of peers from its splitter, first checks if there are
  neighbors in the same subnet (all of them share the same private
  network address). For all those peers, $P_i$ uses the IP address
  $\mathtt{224.0.0.1}$ (all systems on this subnet), (default) port
  $\mathtt{1234}$, to multicast (only) the chunks received from the
  splitter.
\end{enumerate}

\section*{Lab 4: Scaling with P2PSP}
\begin{center}
  \imgw{600}{graphics/icecast-P2PSP.svg}
\end{center}
\begin{itemize}
  \item Splitters can be connected to the Icecast tree as listeners.
\end{itemize}
\lstinputlisting{labs/lab4.sh}

\bibliography{networking,P2P,streaming,misc,simulcasting}
